# NICE7期 | Transformer的无限之路：位置编码视角下的长度外推

## 主题

Transformer的无限之路：位置编码视角下的长度外推

## 时间

2024.1.20 10:30-11:30

## 内容

内容
1. 长度外推的定义及研究动机 （5min）
2. 可外推的位置编码 （20min）
3. 大模型时代的外推方法 （10min）
4. 挑战和开放问题 （5min）
5. QA讨论环节（20mins）

介绍
在自然语言处理领域，Transformer 模型因其在序列建模中的卓越性能而受到广泛关注。然而，Transformer 及在其基础之上的大语言模型（LLMs）都不具备有效长度外推（Length Extrapolation）的能力。这意味着，受限于其训练时预设的上下文长度限制，大模型无法有效处理超过该长度限制的序列。
文本续写和语言延展是人类语言的核心能力之一，与之相对的，长度外推是语言模型智能进化的重要方向，也是在大模型时代最为高效的将模型的能力迁移到长序列数据的重要方法，对该问题的研究兼具理论价值和应用价值。因此，大量的相关工作持续涌现，在不断扩展语言模型能力边界的同时，也呼唤一篇系统性的综述来对这一领域进行概览。
因此，我们从位置编码（Position Encoding, PE）的角度出发，全面地总结了 Transformer 模型在长度外推方面的研究进展，系统地回顾了各种旨在增强 Transformer 长度外推能力的方法，主要包括可外推的位置编码和基于这些位置编码的拓展方法。

### 入群

欢迎加入NICE每周分享交流群，可与NICEer唠嗑，以及第一时间收到后续NICE分享报告的通知。加群通过小助手认证，群内无广告。

<div align=center>
<img src="../images/nice_41_qr.png" width = "200">
<p>备注【昵称-单位-方向-NICE入群】</p>
</div>
