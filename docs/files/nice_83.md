# NICE 83期 | 解码LLM的神经元电路：知识、算术与推理的机制可解释性新进展

## 主题

解码LLM的神经元电路：知识、算术与推理的机制可解释性新进展

## 时间

2025.08.30 周六 20:00

## 内容

本次分享聚焦于大语言模型与多模态大模型的机制可解释性。分享嘉宾将结合自己近期在机制可解释性的系列工作，说明模型内部如何表征与调用事实知识、完成算术计算、以及进行（潜在）多跳推理；同时展示这些理解如何转化为模型改造、参数融合与可视化工具，从而提升能力与可靠性。
本次分享围绕下几点展开： 
1 什么是机制可解释性（MI），以及机制可解释性对于建立更加安全可靠更好的大模型来说有什么重要意义。 
2 机制可解释性的工具方法有哪些，它们从何而来？
• 首先从decoder-only大模型的结构出发，解释残差流、神经元、回路和特征等概念。
• 基于这些概念介绍不同的重要性归因可解释性方法，包括基于因果追踪的方法、基于Logit的方法（LogitLens、神经元识别）、启发式的方法等。
3 如何使用这些MI工具解释不同的任务机制
嘉宾将结合近期工作介绍如何利用MI工具分析LLM在知识、算术、上下文理解、多步推理等不同任务场景下可解释性机制。
4 Anthropic的可解释性之路
最后将通过梳理Anthropic在机制可解释性领域的探索之路，展望MI的未来发展方向。

### 入群

欢迎加入NICE每周分享交流群，可与NICEer唠嗑，以及第一时间收到后续NICE分享报告的通知。加群通过小助手认证，群内无广告。

<div align=center>
<img src="../images/nice_41_qr.png" width = "200">
<p>备注【昵称-单位-方向-NICE入群】</p>
</div>
