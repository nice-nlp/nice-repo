# NICE 50期 | 大模型的高效新能源：数据合成与自动化评估

## 主题

大模型的高效新能源：数据合成与自动化评估

## 时间

2025.3.23 10:30 am

## 内容

论文介绍：（题目：AI监督带来的风险和挑战）基于大模型的数据合成和评估已经成为模型开发的常见范式，然而由于数据合成模型和评估模型相关性所带来的潜在污染问题却缺乏探索。在本篇工作里，我们定义了三种常见的模型相关性：相同模型、继承关系、同一模型家族，并通过多个LLM基线和基准测试实验证实了偏好泄露的存在。进一步分析表明，偏好泄露比已知的LLM评估偏差更隐蔽，且难以检测。 

论文介绍：大型语言模型在复杂推理任务上表现出色，并且将其推理能力蒸馏到小型模型中已显示出一定的潜力。然而，我们发现了一个有趣的现象，称之为Small Model Learnability Gap：小于等于 3B的模型并不一定能稳定地从蒸馏长思维链(long CoT)或蒸馏更大的教师模型中获益。相反，当它们蒸馏更短或更小的教师模型的推理可能表现更佳，因为这种方式更符合它们固有的学习能力。此外，数学专有模型的learnability gap远小于通用模型，说明这种现象可能来自于小模型领域知识的不足。为了解决这一问题，我们提出了一种简单的策略叫做混合蒸馏（Mix Distillation），它通过以一定比例混合长短 CoT 数据或混合更大和更小的教师模型的蒸馏数据。实验结果表明，与仅使用单一类型数据训练相比，混合蒸馏提升了小模型的推理能力。这一发现揭示了直接从强大模型进行蒸馏的局限性，并强调了在推理能力迁移过程中适配推理数据复杂度的重要性。 

论文介绍：现有的合成数据生成方法仍然存在泛化性不足，可控性有限，多样性较低和幻觉问题。针对这些问题，本文提出 DataGen，一个基于LLMs的综合数据生成框架，旨在提高数据的多样性、准确性、可控性和泛化能力。DataGen支持所有类型的文本数据，采用采用自反思（Self-Reflection）和自增强（Self-Enhancement）机制来提升数据质量；同时利用基于代码的验证并结合RAG技术，确保生成文本的准确性。其被用于LLM动态基准测试和数据增强，并证明对提升LLM的推理能力和知识泛化能力有显著作用。 

### 入群

欢迎加入NICE每周分享交流群，可与NICEer唠嗑，以及第一时间收到后续NICE分享报告的通知。加群通过小助手认证，群内无广告。

<div align=center>
<img src="../images/nice_41_qr.png" width = "200">
<p>备注【昵称-单位-方向-NICE入群】</p>
</div>
