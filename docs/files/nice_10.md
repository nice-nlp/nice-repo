# NICE 10期 | 全栈大模型微调框架LLaMA Factory：从预训练到RLHF的高效实现

## 主题

全栈大模型微调框架LLaMA Factory：从预训练到RLHF的高效实现

## 时间

2024.3.9 10:30-11:30

## 内容

项目地址：https://github.com/hiyouga/LLaMA-Factory 

内容概要
LLaMA Factory是一个高效、易用、可扩展的开源全栈大模型微调框架，半年内在GitHub开源社区获得10000关注，并得到Hugging Face、Avalon Labs、美团等多家国内外企业的关注或落地应用。本次分享将从大模型高效训练的角度详细剖析LLaMA Factory的构建动机与组成模块，包括上百种大模型的全栈微调适配原理，LoRA算子优化加速方法，多种微调Trick集成思路等等。

引言部分
LLaMA、Mistral、Qwen、ChatGLM等国内外大模型在开源后得到了众多关注，然而如何将大模型适配到各自的任务上，则依赖于对大模型的进一步微调。LLaMA Factory作为一个通用、高效的大模型微调框架，能在消费级的硬件资源上对上百种大模型完成调优，并使用不同形态的数据集解锁大模型的通用理解、多轮对话、工具调用等能力。LLaMA Factory通过简单高效的实现，使我们能够在短时间内开展多样化的科学研究和工程应用。

### 入群

欢迎加入NICE每周分享交流群，可与NICEer唠嗑，以及第一时间收到后续NICE分享报告的通知。加群通过小助手认证，群内无广告。

<div align=center>
<img src="../images/nice_41_qr.png" width = "200">
<p>备注【昵称-单位-方向-NICE入群】</p>
</div>
