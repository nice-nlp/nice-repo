# NICE6期 | Deita: 针对大模型对齐中高质量指令数据筛选的研究及其相关工具

## 主题

Deita: 针对大模型对齐中高质量指令数据筛选的研究及其相关工具

## 时间

2024.1.13 10:30-11:30 

## 内容

内容
1. Deita概括：工具、数据与模型 (5mins)
2. 大模型对齐进展介绍（5 mins）
3. 数据高效指令微调介绍（10mins）
4. Deita的数据筛选策略与研究发现（15mins）
5. 实验发现与总结（5mins）
6. QA讨论环节（20mins

介绍
指令微调是大语言模型对齐人类使用偏好，价值观的关键技术。先前的工作发现，利用少量的高质量指令微调数据进行训练，大语言模型就能在对齐用户偏好上取得不错的性能。
然而，现阶段我们仍然缺少对指令微调中高质量数据挑选较为系统的研究，也尚不清楚仅用少量高质量指令微调数据训练出的模型性能上限到底在哪里。
在本篇工作中我们首先系统探究了不同的指令微调数据筛选方法的效果，并且提出了一种简单有效的Score-first Diversity-aware数据筛选策略。我们使用少量基于该策略筛选的高质量数据，训练得到了我们的Deita (Data-Efficient Instruction Tuning for Alignment) 模型。
实验显示，我们的模型仅仅通过6千条自动筛选的微调（SFT）数据和一万条随机采样的DPO (Direct Preference Optimization) 数据进行训练，就可以在大模型对齐公开榜单MT-Bench和AlpacaEval上取得7.55和90.06%的性能，超越一众使用了10倍以上数据量进行微调的大语言模型，取得了“四两拨千斤“的效果。
我们的数据筛选工具、数据以及模型都开源在了github[1]，欢迎大家使用以及提出意见，我们会持续更新我们的Deita。

### 入群

欢迎加入NICE每周分享交流群，可与NICEer唠嗑，以及第一时间收到后续NICE分享报告的通知。加群通过小助手认证，群内无广告。

<div align=center>
<img src="../images/nice_41_qr.png" width = "200">
<p>备注【昵称-单位-方向-NICE入群】</p>
</div>
