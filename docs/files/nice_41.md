# NICE 41期 | 大模型评估的新视角：理论指标创新与下游任务应用

## 主题

大模型评估的新视角：理论指标创新与下游任务应用

## 时间

2024.12.28 10:30-12:00 周六

## 内容

新型评估指标：Diff-eRank

如何全面、科学地评估大语言模型的性能是一个重要挑战。传统方法仅关注模型预测与标注标签的比较，无法深入分析模型的内部信息处理。对于多模态大模型，现有评估指标也无法评价模态对齐等重要维度。为此，我们提出了一种新型评估指标Diff-eRank，基于模型表征的有效秩，量化大语言模型在训练前后如何剔除冗余信息，评估模型性能。Diff-eRank通过分析模型的隐藏表征，而非输出结果，来评估模型表现。对于多模态模型，我们设计了基于有效秩的评估方法，评估模态对齐性能，证明了主流多模态大模型的对齐能力。

该工作已被NeurIPS2024接收。

LLM医学评估：MultifacetEval

大语言模型在医学领域的应用已经受到了研究者们广泛的关注。当前，一些大语言模型在一系列医学基准评测集(MedQA, MMLU-clinical)上取得了显著的成绩，但它们在实际医学应用场景中表现欠佳，与它们的评测集表现之间存在较大的差距。
在本报告中，我将介绍我们设计的一种新型大模型医学多面评测方法(MultifacetEval)，其从多个医学知识运用维度对大语言模型进行评测。通过对十余种大语言模型的评测，我们发现当前大语言模型对医学知识的掌握程度仍有较大提升空间，可能是它们在真实医学场景中表现不佳的可能原因之一。

本工作已被IJCAI2024接收。

### 入群

欢迎加入NICE每周分享交流群，可与NICEer唠嗑，以及第一时间收到后续NICE分享报告的通知。加群通过小助手认证，群内无广告。

<div align=center>
<img src="../images/nice_41_qr.png" width = "200">
<p>备注【昵称-单位-方向-NICE入群】</p>
</div>
