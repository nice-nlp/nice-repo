# NICE 82期 | 打破长视频理解极限！Video-XL & Video-XL-2: 小时级超长视频理解大模型

## 主题

打破长视频理解极限！Video-XL & Video-XL-2: 小时级超长视频理解大模型

## 时间

2025.08.28 (周四) 20:00

## 内容

论文信息
[CVPR 2025 Oral] Video-XL: Extra-Long Vision Language Model for Hour-Scale Video Understanding

内容介绍
尽管当前的多模态大语言模型（MLLM）在视频理解方面取得了显著进展，理解超长视频仍然面临巨大挑战。一方面，视频时长的增加会导致大量的视觉token，令具有固定上下文长度的LLM难以有效处理。另一方面，视频长度的增长也带来了高昂的计算成本，包括显存消耗和计算复杂度的增加。为了解决这些问题，我们提出了Video-XL模型，充分发挥LLM的原生能力对长视觉序列进行高效压缩。具体来说，我们将长视觉序列分段编码，并在每段内将普通的视觉相关特征压缩为“VST”表示。同时，我们提出了一种动态压缩策略，依据视频的时序特征进行灵活调整，以达到最佳压缩效果。此外，为了应对高质量长视频数据的稀缺问题，我们不仅通过单图和多图知识的结合促进了长视频理解，还创新性地提出了长视频动作事件排序数据集。实验结果表明，Video-XL在多个长视频理解benchmark中表现出色，超越了同级别的其他模型，并在保证高质量压缩的同时，保持了优异的理解效果。同时，Video-XL在效率和效果之间实现了卓越的平衡，在视频“大海捞针”任务中，单个80GB GPU即可处理2048帧数据，且准确率接近95%。

论文信息
Video-XL-2: Towards Very Long-Video Understanding Through Task-Aware KV Sparsification

内容介绍
在Video-XL一代的基础上，我们进一步提出了Video-XL-2，其具有更优越的模型的表现以及更高效的，灵活的KV压缩机制。Video-XL-2包含两个关键技术：基于块的预填充和双层级键值解码。基于块的预填充将帧序列划分为多个块，在块内使用全注意力、块间采用稀疏注意力，大幅降低计算与内存开销。在解码阶段，双层级键值解码根据各块与任务的相关性，选择性地加载密集或稀疏的键值缓存，进一步提升内存效率并增强对细粒度信息的捕捉能力。Video-XL-2在多个长视频理解基准上达到领先水平，超越大多数主流轻量级模型，甚至优于部分大型模型。同时具备卓越的效率，可在单张NVIDIA A100（80GB）GPU上处理超过10,000帧视频，并在数秒内完成数千帧的推理。

### 入群

欢迎加入NICE每周分享交流群，可与NICEer唠嗑，以及第一时间收到后续NICE分享报告的通知。加群通过小助手认证，群内无广告。

<div align=center>
<img src="../images/nice_41_qr.png" width = "200">
<p>备注【昵称-单位-方向-NICE入群】</p>
</div>
