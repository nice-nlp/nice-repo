# NICE 74期 | 从大模型的安全对齐到欺骗性对齐

## 主题

从大模型的安全对齐到欺骗性对齐

## 时间

2025.07.11 (周五) 10:00

## 内容

论文列表
- Language Models Resist Alignment: Evidence From Data Compression， https://arxiv.org/abs/2406.06144
- AI Alignment: A Comprehensive Survey，https://arxiv.org/abs/2310.19852
- Aligner: Efficient Alignment by Learning to Correct，https://arxiv.org/abs/2402.02416
- Mitigating Deceptive Alignment via Self-Monitoring， https://arxiv.org/abs/2505.18807

内容介绍
近年来，学术界和产业界持续关注通过对齐（Alignment）技术确保大模型与人类意图的一致性，尤其是在数学和代码等场景下的指令遵循能力。然而，实验结果表明，即便采用了精心设计的对齐流程，这些机制依然可能被有意或无意地规避，对齐效果的可靠性受到广泛质疑。那么，对齐技术究竟能否实现真正意义上的“对齐”？ 
本次分享将视角从传统的大模型安全对齐拓展至当下备受关注的欺骗性对齐问题，并从机理层面剖析类似胡克定律的“弹簧效应”——即大模型参数内在的“弹性”现象：模型对对齐目标表现出一定的抗拒性，倾向于回归其预训练阶段形成的稳定行为分布。 
从这一“弹性”理论出发，我们对现有对齐流程提出三点关键建议。
与此同时，我们将深入探讨当前对齐领域面临的核心挑战，包括抗拒对齐（Resist Alignment）、欺骗性对齐（Deceptive Alignment）等高阶安全风险。最后，还将分析传统安全对齐方法在应对高阶安全风险时所面临的不足与挑战。 

### 入群

欢迎加入NICE每周分享交流群，可与NICEer唠嗑，以及第一时间收到后续NICE分享报告的通知。加群通过小助手认证，群内无广告。

<div align=center>
<img src="../images/nice_41_qr.png" width = "200">
<p>备注【昵称-单位-方向-NICE入群】</p>
</div>
