# NICE16期 | 如何加速大语言模型推理？万字长文综述大语言模型高效推理技术

## 主题

如何加速大语言模型推理？万字长文综述大语言模型高效推理技术

## 时间

2024.7.7 上午10:30-11:30 

## 内容

论文：A Survey on Efficient Inference for Large Language Models
地址：https://arxiv.org/pdf/2404.14294 

内容
1. 研究背景与基础概念介绍
2. 分层、分领域综述高效推理领域的技术
    2.1: 数据层
    2.2: 模型层
    2.3: 系统层（简略）
3. 未来方向讨论与结论
4. QA

研究背景
大语言模型（Large Language Models, LLMs）在近些年受到了学术界和工业界的广泛关注，得益于其在各种语言任务上的突出表现，大语言模型推动了各种人工智能应用（如ChatGPT、Copilot等）的发展。然而，大语言模型的应用部署受限于其巨大的推理开销，如何提升大语言模型的推理效率，优化推理的延时、吞吐、功耗和存储等指标，是很多研究工作关注的目标。本次分享报告将综述大语言模型高效推理领域的各类技术，报告将首先分析当前大语言模型推理过程的效率瓶颈，深入分析其根本原因。基于此分析，报告将目前的优化方法划分为三个层次（即数据层、模型层和系统层），并分层、分子领域进行技术介绍和领域总结。最后，报告将深入讨论高效推理领域未来应当关注的场景、挑战和路线，为研究者提供可行的研究方向。 

### 入群

欢迎加入NICE每周分享交流群，可与NICEer唠嗑，以及第一时间收到后续NICE分享报告的通知。加群通过小助手认证，群内无广告。

<div align=center>
<img src="../images/nice_41_qr.png" width = "200">
<p>备注【昵称-单位-方向-NICE入群】</p>
</div>
