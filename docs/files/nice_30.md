# NICE 30期 | 在上下文学习中，语言模型究竟学到了什么? 探索结构化任务假说

## 主题

在上下文学习中，语言模型究竟学到了什么? 探索结构化任务假说

## 时间

2024.10.13 15:00-16:00 周日

## 内容

论文：What Do Language Models Learn in Context? The Structured Task Hypothesis. (ACL 2024)
地址：https://arxiv.org/pdf/2406.04216
代码链接: https://github.com/eth-lre/LLM_ICL/

大纲
1. 导论
2. 假设1: 任务选择
3. 假设2: 元学习
4. 假设3: 结构化任务选择
5. 结论

引言
大型语言模型（LLMs）展现了通过演示中的上下文示例学习新任务的能力，这被称为上下文学习（ICL）。因此，许多研究致力于揭示ICL背后的理论。其中一个流行的假设是通过任务选择来解释ICL：LLMs基于演示示例识别任务，并将其泛化到提示中。另一个流行的假设认为ICL是一种元学习形式，即模型在预训练时学习一种学习算法，并将其应用于演示示例。最后，第三种假设认为LLMs利用演示来选择预训练期间学习的任务组合来执行ICL。
我们通过一系列源自常见文本分类任务的实验，实证探讨了这三种解释LLMs上下文学习能力的假设。我们通过反例推翻了前两个假设，并提供了支持第三个假设的证据。我们的结果表明，LLMs可以通过组合预训练期间学习的任务，在上下文中学习新的任务。

### 入群

欢迎加入NICE每周分享交流群，可与NICEer唠嗑，以及第一时间收到后续NICE分享报告的通知。加群通过小助手认证，群内无广告。

<div align=center>
<img src="../images/nice_41_qr.png" width = "200">
<p>备注【昵称-单位-方向-NICE入群】</p>
</div>
